---
title: "Part 2: Turning Zoom Downloads into Datasets"
author: "Andrew P. Knight"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Part 2: Turning Zoom Downloads into Datasets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In the second part of this guide, you will learn how to turn downloadable files from Zoom recordings into datasets that you can analyze in `R` using `zoomGroupStats`. Again, because `zoomGroupStats` relies on [Zoom Cloud recording](https://support.zoom.us/hc/en-us/articles/203741855) features, this guide will focus specifically on the files that you download from the Zoom Cloud. However, the functions in `zoomGroupStats` can also be used on meetings that you record locally. 

This guide will progress from instructions on which files to download from Zoom to how to convert those files into useable datasets. In its most basic form, a research dataset using virtual meetings can be structured as individual meeting participants who are nested within virtual meetings. Individual participants can attend multiple virtual meetings; indeed, individual participants *could* attend multiple virtual meetings at the same time. Individuals can further be members of multiple other organizational units (e.g., groups, teams, departments, organizations). To build a basic, clean dataset, though, what you must know is which individual human being was logged into which virtual meeting.  

## How to Download Files from Zoom

Depending on your research objectives, you will need different output files from Zoom. The components that are currently supported and used in this package are:

1. A *participants* file. This is a .csv file that contains meta-data about your meeting. This is an essential file that should be downloaded for each meeting that you wish to process. To download it:  
    * Log into your Zoom account through a web browser
    * Navigate to the *Reports*
    * Click *Usage Reports* 
    * Scroll to the *Participants* column for your focal meeting
    * Click the linked number of participants
    * Check "export with meeting data" and "show unique users"
    * Click *Export*
1. A *transcript* file. This is a .vtt file that contains Zoom's cloud transcription of the spoken audio during the recorded meeting. 
    * Navigate to the *Recordings* page
    * Click the link indicating the number of items
    * Download the Audio Transcript file
1. A *chat* file. This is a.txt file that contains the record of public chat messages posted during the recorded meeting. Download it from the same page where you accessed the *transcript*. 
1. An *audio* file. This is an .mp4 file that contains the recorded audio during the session. Download it from the same age as the items above.
1. Several different *video* file options. [Zoom's Help Center describes The nature of these different formats](https://support.zoom.us/hc/en-us/articles/360025561091-Recording-layouts). For analyzing facial expressions, one of the most useful is the gallery style video. 

## Naming the Downloaded Files from Zoom 

`zoomGroupStats` is designed to batch proces virtual meetings. Batch processing simply means that you are combining several meetings into a single dataset. Even if you are only analyzing a single meeting, though, it is useful to treat that single meeting as a batch of one. This will help in creating an extensible dataset that you could add to in the future. 

To organize your data for a batch run, you must rename the files in a systematic way and save them in a single directory. To name the files, imagine that each file will have a "prefix" and a "suffix". The prefix will be an identifier for what meeting it came from and the suffix will be an identifier for what data source is in the file. Whereas you can use whatever prefix you choose, the suffix must be standardized as follows: 

| Suffix | Description |
|:---------------|:------------------------------------------------|
| _chat.txt | Used for the chat file for meetings |
| _transcript.vtt | Used for the transcript file for meetings  |
| _participants.csv | Used for the participants file for meetings |
| _video.mp4 | Used for a video file for meetings |

Imagine a sample batch run, then, which includes all four elements for three meetings. The prefixes for the meetings could be "meeting001", "meeting002", and "meeting003". This would yield a total of 12 files, named as follows: 

* meeting001_chat.txt
* meeting001_transcript.vtt
* meeting001_participants.csv
* meeting001_video.mp4
* meeting002_chat.txt
* meeting002_transcript.vtt
* meeting002_participants.csv
* meeting002_video.mp4
* meeting003_chat.txt
* meeting003_transcript.vtt
* meeting003_participants.csv
* meeting003_video.mp4

All 8 files should be saved in a single directory. 

## Prepare a Batch Spreadsheet

Next, you will prepare a spreadsheet in .xlsx format. This spreadsheet tells `zoomGroupStats` how to find your files and what information to process. Practically, this spreadsheet is also helpful for organizing your data and keeping track of what you have downloaded. 

You must use the following structure and column headers for your spreadsheet:

| batchMeetingId | fileRoot | participants | transcript | chat | video |
|:---------------|:---------|:-------------|:-----------|:-----|:------|
|   00000000001  |  /myMeetings/meeting001  |    1   |    1  | 1 | 0 |
|   00000000002  |  /myMeetings/meeting002  |    1   |    1  | 1 | 0 |
|   00000000003  |  /myMeetings/meeting003  |    1   |    1  | 1 | 0 |

The first row in the file is the header, which should mirror the example above. Each subsequent row provides the information for a single meeting. [Here is a sample that you could use](https://github.com/andrewpknight/zoomGroupStats/blob/main/inst/extdata/myMeetingsBatch.xlsx), replacing any rows after the header with your own information.

| Column Name | Description |
|:---------------|:------------------------------------------------|
| batchMeetingId | A string identifier for this particular meeting |
| fileRoot | A string that gives the full path and prefix where the files from this meeting can be found. The final part of this string (e.g., meeting001 above) is how you have named the files downloaded for this meeting.  |
| participants | Binary - 0 if you did not download the participants file, 1 if you did |
| transcript | Binary - 0 if you did not download the transcript file, 1 if you did |
| chat | Binary - 0 if you did not download the chat file, 1 if you did |
| video | Binary - 0 if you did not download a video file, 1 if you did |

## Process your Batch

If you have followed the steps above, turning your Zoom sessions into data should be straightforward using the `zoomGroupStats` package.You should begin by installing the latest version of `zoomGroupStats`. Currently this is done through the `install_github` function from the `devtools` package: 

```{r, eval=FALSE}
devtools::install_github("https://github.com/andrewpknight/zoomGroupStats")
```

After you have installed the package, you can then load it into your environment as usual: 

```{r setup}
library(zoomGroupStats)
```

The first step in turning downloads into data is to process your batch using the `batchProcessZoomOutput` function. 

```{r, eval=FALSE}
batchOut = batchProcessZoomOutput(batchInput="./myMeetingsBatch.xlsx")
```

```{r, echo=FALSE, results="hide"}
batchOut = batchProcessZoomOutput(batchInput=system.file('extdata', "myMeetingsBatch.xlsx", package = 'zoomGroupStats'))
```

`batchInput` gives the path to the batch file that you created by following the steps above. This function will iterate through the meetings listed in the `batchInput` file. For each meeting, the function will detect any of the named files described above and do an initial processing of them.

The output, stored in this example in `batchOut`, will be a multi-item list that contains any data that were available according to the batch instructions. Currently, the following items can be included, if raw files are available: 

### meetInfo & partInfo

These two items provide meta-data about the full set of virtual meetings. These are useful files for nailing down the structure of your full dataset (in terms of individuals nested within meetings) and for creating a unique individual identifier for the people in your dataset. 

`meetInfo` is a data.frame that gives information pulled about the meetings from the participants file downloaded from Zoom. Each row in this file is a meeting: 

```{r}
str(batchOut$meetInfo)
```

`partInfo` is a data.frame that gives the participants in each meeting and any information available in the participants file downloaded from Zoom

```{r}
str(batchOut$partInfo)
```

### transcript & chat

These two items provide parsed text data from the transcribed audio spoken during the meeting and the text-based chat in the meeting. These files are the basis of any further text-based analysis. One important thing to note in processing transcripts is that Zoom timestamps the transcript file anchored on the start of the recording--not at the start of the session itself. The issue here is that a recording may not begin until a period of time after the launch of the session. This means that you could have a transcript file out of sync with the chat file, which begins its timestamp at the start of the session. Resolving this issue requires careful records of when the recording was started or setting up your session to automatically record. 

`transcript` is a data.frame that is the parsed audio transcript file. Each row represents a single marked "utterance" using Zoom's cloud-based transcription algorithm. Utterances are marked as a function of pauses in speech and/or speaker changes. 

```{r}
str(batchOut$transcript)
```


`chat` is a data.frame that is the parsed text-based chat file. Each row represents a single chat message submitted by a user. Non-ASCII characters will not be correctly rendered in the message text.

```{r}
str(batchOut$chat)
```

### rosetta
The final element is called "rosetta" because it will help you deal with one of the most vexxing challenges in analyzing virtual meetings with a large number of participants: The lack of a persistent and unique individual identifier for participants. Because the transcript and chat files rely on people's Zoom display names--and because people can change their display names--you will frequently encounter duplicate names and/or multiple identifiers for the same person. 

From a data structure perspective, what is most important to know is which individual person logged into which virtual meeting. Unfortunately, complications in how Zoom identifies individuals require careful human attention to this issue. To illustrate, consider the following exaggerated example. Arun Jah is an attendee in Meeting A. Arun logs in on his laptop through his corporate account. But, he also logs in on his iPad through his family account to the same meeting. After a few minutes, Arun realizes that his iPad account has his child's name displayed (the child was using it for virtual school). So, he changes his display name. Halfway through the meeting, Arun needs to get in his car to go pick up his child. So, he logs into the meeting on his smartphone. In a raw Zoom dataset, the person "Arun" will show up as four different names--(1) his corporate name that was not changed; (2) his child's name on his iPad; (3) the name he changed his iPad to; and, (4) his mobile phone. Clearly, to properly study human behavior, all of the actions associated with these four names should be attached to "Arun". 

To address this problem, the `rosetta` file compiles every unique display name (by meeting) encountered across the `participants`, `chat`, and `transcript` files. 

```{r}
str(batchOut$rosetta)
```

## Add a Unique Individual Identifier to All Elements

I have found that by exporting the `rosetta` file and manually attaching a unique individual identifier (e.g., number) is a necessary process to ensure that the right data are attached to the right people. In terms of process, here is what I do: 

* Export the `rosetta` file. You can do this in your initial `batchProcessZoomOutput` call as follows: 
```{r, eval=FALSE}
batchOut = batchProcessZoomOutput(batchInput="./myMeetingsBatch.xlsx", exportZoomRosetta="./myMeetings_rosetta_original.xlsx")
```
* Manually review this file, adding a new column with your unique user identifier (e.g., `indivId`). This should be a persistent identifier for the *person*--something that is repeated across multiple meetings that someone is in. Save your file with a new name so that you don't accidentally overwrite it by re-running the command above. 

* Import the reviewed and edited rosetta file. The following command will import the file and add your new identifier to each of the elements that are included in `batchOut`. Going forward, you should use the new individual identifier (e.g., `indivId`) in your analyses. Together with the meeting identifier (e.g., `batchMeetingId`), you will be able to link records to other relevant data that you have collected (e.g., survey data). 

```{r, eval=FALSE}
batchOutIds = importZoomRosetta(zoomOutput=batchOut, zoomRosetta="./myEditedRosetta.xlsx", 
meetingId="batchMeetingId")
```

# Analyzing Data within `transcript` and `chat`

## Cleaning text-based data

## Performing sentiment analysis

Using `textSentiment`

```{r, eval=FALSE}
 transcriptSent = textSentiment(inputData=batchOutIds$transcript, idVar=c('utteranceId'), textVar='utteranceMessage', sentMethods=c('aws', 'syuzhet'), appendOut=FALSE, languageCodeVar='utteranceLanguage')
```

## Performing conversation analysis

Using `textConversationAnalysis`

```{r, eval=FALSE}
 convo.out = textConversationAnalysis(inputData=transcriptSent$aws, inputType='transcript', meetingId='batchMeetingId', speakerId='indivId', sentMethod="aws")
```

## Performing windowed conversation analysis

Using `windowedTextConversationAnalysis`

```{r, eval=FALSE}
 win.convo.out = windowedTextConversationAnalysis(inputData=transcriptSent$aws, inputType='transcript', meetingId='batchMeetingId', speakerId='indivId', sentMethod="aws", timeVar="utteranceStartSeconds", windowSize=600)
```

# Analyzing Video from Zoom

## Parsing Zoom Video feed

Using `grabVideoStills`

```{r, eval=FALSE}
grabVideoStills(inputVideo='sample_gallery_video.mp4', sampleWindow=45, stillPath="")
```

## Analyzing attributes of detected faces

Using `videoFaceAnalysis`

```{r, eval=FALSE}
vid.out = videoFaceAnalysis(inputVideo="sample_gallery_video.mp4", recordingStartDateTime="2020-04-20 13:30:00", sampleWindow=30, facesCollectionID="group-r")
```