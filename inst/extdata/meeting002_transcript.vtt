WEBVTT

1
00:00:04.859 --> 00:00:07.410
Andrew Knight: Okay, so we're recording. We're streaming

2
00:00:09.540 --> 00:00:12.990
Andrew Knight: We have that setup. Okay.

3
00:00:15.630 --> 00:00:17.760
Andrew Knight: It's like Mary Kate's here. I'll let her in.

4
00:00:19.980 --> 00:00:21.240
Andrew Knight: Gonna make her a host to

5
00:00:24.000 --> 00:00:26.070
Paul McCartney: She just got back from a vacation or something.

6
00:00:27.330 --> 00:00:27.870
George Harrison: Mary Kate.

7
00:00:28.560 --> 00:00:31.110
George Harrison: I think she was on a vacation for a while.

8
00:00:31.650 --> 00:00:33.630
Ringo Starr: Oh, nice. See how that one.

9
00:00:37.560 --> 00:00:38.100
Andrew Knight: America, Kate.

10
00:00:39.480 --> 00:00:41.190
John Lennon: Hi, how's it going good.

11
00:00:42.930 --> 00:00:43.950
John Lennon: It's everything good to go.

12
00:00:44.790 --> 00:00:45.990
George Harrison: Thanks. So great.

13
00:00:46.740 --> 00:00:49.350
Andrew Knight: Yeah, I can start letting people in if that's

14
00:00:50.880 --> 00:00:53.070
Andrew Knight: That's useful. Yeah.

15
00:00:53.760 --> 00:00:55.740
John Lennon: Whatever you whatever is easiest for you.

16
00:00:56.820 --> 00:01:04.200
John Lennon: So pop up screen that I saw why I said I liked the pop up screen that I saw before I got in. I had seen that before.

17
00:01:04.860 --> 00:01:05.370
Andrew Knight: What was it

18
00:01:05.490 --> 00:01:10.260
John Lennon: It said host is waiting to let you in. And it said like the name of the event.

19
00:01:11.400 --> 00:01:11.700
Andrew Knight: Okay.

20
00:01:15.270 --> 00:01:18.300
Andrew Knight: So we will. I'll do just a brief.

21
00:01:19.560 --> 00:01:36.570
Andrew Knight: Brief very brief intro because I baked. A lot of it into the pre set slide that will circulate throughout. So I'll just do a brief very brief intro before I intro you throw it over to you and you can share your screen then and and dive in. Awesome. Thanks. Okay.

22
00:01:36.780 --> 00:01:41.490
Paul McCartney: Do you need to look at that. That select part of a screen for your PowerPoint again.

23
00:01:41.790 --> 00:01:45.600
Paul McCartney: I think I did. Let me just try share screen. Yeah.

24
00:01:48.030 --> 00:01:48.630
Paul McCartney: It's not good.

25
00:01:50.220 --> 00:01:50.670
John Lennon: Yeah.

26
00:01:51.750 --> 00:01:53.790
Paul McCartney: And it works. You're seeing it move

27
00:01:54.690 --> 00:01:57.270
John Lennon: Yep, yep. It looks great there you

28
00:01:57.450 --> 00:01:58.740
Paul McCartney: Go back to the original

29
00:02:05.670 --> 00:02:15.960
Andrew Knight: All right, Mary Kate, if anything goes off, I'll be watching the chat if you just text me or like enter anything into the chat there that needs to

30
00:02:16.110 --> 00:02:16.770
Paul McCartney: Be adjusted

31
00:02:16.830 --> 00:02:19.860
Paul McCartney: Like private someone cell phone, just in case.

32
00:02:20.220 --> 00:02:21.540
Paul McCartney: Something goes horribly wrong.

33
00:02:22.440 --> 00:02:28.890
Andrew Knight: Yep. Oh. Enter mine in a direct private chat, just so that it's always there for you. Thanks.

34
00:02:30.060 --> 00:02:30.420
And that

35
00:02:35.340 --> 00:02:36.660
Andrew Knight: And I have that sitting here.

36
00:02:36.960 --> 00:02:45.630
Paul McCartney: Too. I'm just gonna call that number so that you have it 321-584-0624. Awesome. Thanks.

37
00:02:46.500 --> 00:02:47.640
Andrew Knight: So were you the 917

38
00:02:48.000 --> 00:02:49.320
Yes. Okay.

39
00:02:50.670 --> 00:02:52.260
Andrew Knight: Alright, so I'm gonna let people in

40
00:10:15.210 --> 00:10:25.080
Andrew Knight: Hello everyone. Welcome, welcome to our program this afternoon or this evening or this morning, depending on where you're joining us from

41
00:10:25.830 --> 00:10:36.450
Andrew Knight: You are more than welcome. Of course to unmute your video if you want to join the session and have a presence here with us if that's possible. It's always a wonderful way to build the community.

42
00:10:36.870 --> 00:10:45.120
Andrew Knight: My name is Andrew night. I'm a professor of organizational behavior in Olin business school. And I'm also the academic director of lifelong learning.

43
00:10:45.300 --> 00:11:01.830
Andrew Knight: And if there's one thing I've learned so far from online teaching it is that there is enormous value in having the community that you're a part of right there in front on the screen. And so if you aren't too shy to broadcast your video, please do so.

44
00:11:02.430 --> 00:11:08.910
Andrew Knight: We have an outstanding program ahead. And so I just want to take a couple of minutes here at the outset.

45
00:11:09.240 --> 00:11:15.150
Andrew Knight: To share with you how this program fits into some of the goals and the work that we're doing.

46
00:11:15.480 --> 00:11:24.180
Andrew Knight: for lifelong learning and so let me just share a couple of slides at the outset, before we welcome Professor liberty visitors who is going to be

47
00:11:24.600 --> 00:11:33.450
Andrew Knight: Sharing her expertise and knowledge with us today. As you may or may not know Olin lifelong learning is an initiative.

48
00:11:33.930 --> 00:11:42.990
Andrew Knight: That is specifically focused on providing opportunities for alumni to engage in continuous development and the rationale for this initiative.

49
00:11:43.530 --> 00:11:57.030
Andrew Knight: Is very much the fact that we make a promise in our vision and our mission statement to provide a return on investment for alumni over the course of their entire careers. And so that's what we are.

50
00:11:57.360 --> 00:12:04.590
Andrew Knight: Working on with the Lifelong Learning Initiative, which is one quadrant of olins always Olin initiative.

51
00:12:06.300 --> 00:12:11.460
Andrew Knight: As you've seen in some of the slides at the outset we are building currently

52
00:12:12.060 --> 00:12:25.650
Andrew Knight: And testing currently a platform that will support alumni learning in community. And so this is a platform that's going to be used to deliver content, similar to what we're going to experience today, but also other

53
00:12:26.010 --> 00:12:38.850
Andrew Knight: events that happen on campus, other kinds of thought leadership from our faculty as well as from alumni. And so this platform is going to be steadily rolling out in the weeks and months that come

54
00:12:39.390 --> 00:12:44.430
Andrew Knight: You'll be able to find archived content things that have happened at the school in the past that we think are relevant.

55
00:12:44.730 --> 00:12:57.510
Andrew Knight: And there will be opportunities for you to engage with your fellow alumni around some of those pieces of content so that you're sharing your expertise wisdom and insights with one another.

56
00:12:57.960 --> 00:13:05.250
Andrew Knight: Now as I mentioned at the start, we are so fortunate today to have with us. Professor liberty visitors.

57
00:13:05.670 --> 00:13:14.520
Andrew Knight: Who is a Professor of Practice of data science here in the business school and she is someone who truly practices. What she preaches

58
00:13:14.910 --> 00:13:24.300
Andrew Knight: She is active in disseminating her knowledge and expertise with respect to statistics data and analytics through so many different channels.

59
00:13:24.690 --> 00:13:36.420
Andrew Knight: Whether that is through the popular media where you might encounter some of her work and commentary, or through doing things like writing a book which is coming out here on the horizon.

60
00:13:36.840 --> 00:13:55.740
Andrew Knight: Just this month. And so we are so fortunate to have someone who is skilled and has deep expertise in this topic, and at the same time someone who is a skilled communicator about this topic. And so without further ado, please join me in welcoming Professor liberty that hurt.

61
00:13:57.180 --> 00:14:05.850
Paul McCartney: Hi, everybody. Thank you. I think I need to fire my PR person. And have you, Andrew. That was great. Um, does the screen. Look. Okay. Can you all see it.

62
00:14:06.240 --> 00:14:14.310
Paul McCartney: I think I hope I shared it right I'm learning zoom. Okay. Um, thank you all so much for having me here today I wanted to sort of

63
00:14:15.030 --> 00:14:19.950
Paul McCartney: dive right in. I have these two graphs or two if you get bored listening to me talk

64
00:14:20.280 --> 00:14:32.610
Paul McCartney: But, um, you know, we've lived as humanists in our decision making for a very long time we go off our thoughts or opinions, our experience our gut and we are now living in this era of data ism.

65
00:14:33.060 --> 00:14:40.980
Paul McCartney: Where we have data drive our decisions, you know, from climate change to health care the refugee crisis. These all encompassing issues.

66
00:14:41.400 --> 00:14:50.310
Paul McCartney: But also in our everyday lives. You know, I don't go to the bookstore anymore. Amazon tells me what to read or dating apps tell you who you're compatible with

67
00:14:50.700 --> 00:15:01.800
Paul McCartney: And I read an article like two or three days ago from new research that red wine is terrible for you and I swear. Two days later I read that red wine is wonderful for you and you should drink it.

68
00:15:02.340 --> 00:15:13.890
Paul McCartney: And it feels almost that humanism and data ism, or sort of pushing back against each other right now. Some people want to still go with that gut instinct and others want to have the drive are every decision.

69
00:15:14.280 --> 00:15:24.300
Paul McCartney: But really the future is about bringing them together and that's what we're going to sort of touch on and have a taste of today is how we can get incredible ideas from data.

70
00:15:24.900 --> 00:15:33.870
Paul McCartney: But we also need to use that human touch. And I also want to say please use common questions, anything you want in the chat and makes it a lot more fun.

71
00:15:34.290 --> 00:15:47.130
Paul McCartney: Throughout the whole thing and I'll respond as we go. Um, so I want to start before we go into our many examples. And by the way, all these examples are short. So if one's boring. Just wait a couple minutes moving to a new one.

72
00:15:47.700 --> 00:16:05.160
Paul McCartney: Um, I wanted to visit with a French monk from the 17th century Blaise Pascal. You might also remember them from high school without Pascal's triangle so Pascal was a French monk who had a crisis of faith, but he decided to analyze his data.

73
00:16:06.330 --> 00:16:20.550
Paul McCartney: He felt that he had four scenarios. First, God doesn't exist, but he chooses to believe in God. He may live a wasted life with false belief, but when he dies, nothing happens.

74
00:16:21.300 --> 00:16:30.990
Paul McCartney: Now, he could not believe in God and God doesn't exist, and he may not have lived a wasted life of false belief, but again, when he dies, nothing happens.

75
00:16:32.310 --> 00:16:40.350
Paul McCartney: Now the third option God exists, and he believes in God, when he dies, he has the best case scenario heaven for him.

76
00:16:40.980 --> 00:16:48.240
Paul McCartney: But if God exists, and we don't believe in God. The fourth scenario, then it's eternal Hellfire really bad thing.

77
00:16:48.810 --> 00:16:58.650
Paul McCartney: So what Pascal decided to do was to minimize the risk of the bad thing happening by believing in God and maximizing the potential is a good thing.

78
00:16:59.010 --> 00:17:05.220
Paul McCartney: So he ruled out this possibility and left a 5050 chance of the best thing happening.

79
00:17:05.820 --> 00:17:19.260
Paul McCartney: And that's really what data science is it's taking information from past and current events to predict the likelihood of a future event happening really the closest thing to a crystal ball. But the world has

80
00:17:19.740 --> 00:17:29.940
Paul McCartney: The only difference between us and Pascal is we don't have four scenarios or four pieces of information we have endless amounts of data that is telling us what to do.

81
00:17:30.300 --> 00:17:42.030
Paul McCartney: And we also have something else. We're not sitting in a monastery, while we do this, we are having governments, businesses companies managers customers, clients even scientists, researchers

82
00:17:42.450 --> 00:17:56.550
Paul McCartney: Trying to inform manipulate or persuade us using this data. So we need to be able to ask the right questions when data comes to us from a report or study or anything comes to us.

83
00:17:56.880 --> 00:18:08.640
Paul McCartney: I want to discuss the questions that I ask every time I see one of these things. So we're going to have our for questions. And we're going to have examples of how if someone had just asked those questions.

84
00:18:08.910 --> 00:18:17.190
Paul McCartney: Everything would have been averted. The downside would have been minimized and the upside maximized. So let's start with our first question, who

85
00:18:18.720 --> 00:18:33.810
Paul McCartney: OJ Simpson, one of the most infamous criminal trials in American history to remind you. Oh Jay was an NFL superstar accused of murdering his ex WIFE NICOLE SIMPSON AND her lover Ronald while Goodman. I'm sure all of a lot of you remember the

86
00:18:34.260 --> 00:18:42.660
Paul McCartney: Case, and I'm sure a lot of you who are a little bit younger might remember one the Kardashian father is one of his lawyers, just to try to give some parallels there.

87
00:18:43.290 --> 00:18:54.630
Paul McCartney: Um, but, Alan Dershowitz whatever your personal feelings of him might be a fate is a famed legal mind in America, and he made a very interesting statistical argument during the trial.

88
00:18:55.110 --> 00:19:04.980
Paul McCartney: He said that while it was known and definite that OJ beat Nicole absolutely no contest. So the fact that he physically abused her that it didn't matter.

89
00:19:05.610 --> 00:19:23.190
Paul McCartney: Because 4 million women in the United States are abused by their domestic partners, every year, but only one in 2500 of them are then murdered by their domestic partner. So the chance that OJ did it is one in 2500 and you can't convict someone on a one in 2500 chains.

90
00:19:24.360 --> 00:19:43.830
Paul McCartney: However, what the jury and most certainly the prosecution should have realized is that the statistic that Mr Dershowitz stated was completely irrelevant and here's why and Mr Dershowitz situation we have a living women who are currently domestic victims of domestic abuse.

91
00:19:44.850 --> 00:19:54.090
Paul McCartney: But at the time of the trial. NICOLE SIMPSON WAS NOT A living woman who's a victim of domestic abuse, whose chance of dying is one in 2500

92
00:19:54.660 --> 00:20:05.730
Paul McCartney: But she's a murdered woman who was a victim of domestic abuse. We don't want to know the statistic about living women. We want to know the statistic about murdered women.

93
00:20:06.120 --> 00:20:12.510
Paul McCartney: Who were victims of domestic abuse. And the question we want to know is that if you were a murdered woman.

94
00:20:13.230 --> 00:20:23.400
Paul McCartney: Who was a victim of domestic abuse, what is the chance that the guy who abused you murdered you versus being the victim of some random homicide.

95
00:20:23.910 --> 00:20:33.270
Paul McCartney: And in that case, the chance is nine and 10 so the chance that OJ killed Nicole was actually 90% not one in 2500

96
00:20:33.900 --> 00:20:39.210
Paul McCartney: Though who we really wanted to know this statistic about changed everything.

97
00:20:39.720 --> 00:20:48.930
Paul McCartney: And it is so easy to miss the prosecution had their entire careers writing on this case, the whole world was watch it and they missed it.

98
00:20:49.560 --> 00:21:01.890
Paul McCartney: This simple slip of the tongue of who we really want to know our data about living women who are victims murdered women who were changes everything. So that who question is integral whenever you get data.

99
00:21:03.150 --> 00:21:12.930
Paul McCartney: Let's look at one more example of that Abraham Wald was a Jewish statistician who'd been locked out of the University positions and fled to the US before World War Two.

100
00:21:13.500 --> 00:21:15.360
Paul McCartney: To avoid persecution and hungry.

101
00:21:16.170 --> 00:21:25.350
Paul McCartney: And he was recruited to help with the Allied cause and look at plane bombers that came back, he was told the analyze the bullet wounds on the plane bombers that came back.

102
00:21:25.620 --> 00:21:35.190
Paul McCartney: And decide which area of the plane that he should reinforce. So my question is, if you're Abraham walled, how do you decide by looking at these planes.

103
00:21:35.550 --> 00:21:39.510
Paul McCartney: What area, you should reinforce if you reinforce 10% of the plane.

104
00:21:40.080 --> 00:21:57.210
Paul McCartney: And he started with this data. This is the data. He had of all the planes that had come back bullet holes per square foot of the section of the plan. So just take one second, five seconds and think, where you would reinforce the plane. If you were Walt. Given this data.

105
00:21:59.160 --> 00:22:02.670
Paul McCartney: Anyone is brave enough to put it into the chat. I'll be very impressed.

106
00:22:04.590 --> 00:22:06.060
Paul McCartney: Real cockpit. Great.

107
00:22:07.440 --> 00:22:10.320
Paul McCartney: Anywhere but we have everyone is too smart here.

108
00:22:12.780 --> 00:22:20.100
Paul McCartney: Where the red dots are red gunner everyone is really smart here okay engines. So what most people think

109
00:22:20.460 --> 00:22:31.290
Paul McCartney: And what most people say is the area where there are the most bullets. Right. So the wings, the fuselage where the dots are the areas most bullets. That is what most people think and the most obvious answer.

110
00:22:31.740 --> 00:22:43.950
Paul McCartney: What Walt is so famous for doing is saying that's actually not where we put it where we need to reinforce the planes or the undamaged parts and here's why.

111
00:22:44.580 --> 00:22:51.660
Paul McCartney: We have to who's we have planes that crashed abroad, the planes, the bombers that didn't make it back.

112
00:22:52.020 --> 00:23:03.330
Paul McCartney: And we have the planes that wall does able to see that we have did trivia. Trivia, I just saw this question in the chat, maybe lose my train of thought the trivia that came back. Now the planes that returned home.

113
00:23:03.660 --> 00:23:12.510
Paul McCartney: So we have two samples planes that crashed abroad planes that returned home, these are the ones come and see my cursor. I hope so. So I'm like pointing at the screen to which obviously you can see

114
00:23:12.990 --> 00:23:21.390
Paul McCartney: The planes that returned home, or what Walt was able to see and those planes when they got hit on the wings or the cockpit.

115
00:23:22.410 --> 00:23:28.500
Paul McCartney: Right here. There's the cockpit. This is our engine when they got hit in the wings. They did their job. They made it back.

116
00:23:29.430 --> 00:23:38.340
Paul McCartney: They were not hit in the cockpit or the engine, the planes that crashed abroad, when they were hit in the cockpit or engine. They couldn't make it back.

117
00:23:38.940 --> 00:23:51.720
Paul McCartney: So, those who were looking at, or sometimes ones we can't even see and it gives us a whole nother answer of where we should be reinforcing the planes, so that both groups, both samples are able to make it back.

118
00:23:54.000 --> 00:24:01.950
Paul McCartney: So this brings us to our second question we have our first have who is the data really about, who do we want to know this data about and next

119
00:24:02.190 --> 00:24:07.980
Paul McCartney: Is what exactly are we, why are we prone to making this type of mistake error. Very good question. Andrew

120
00:24:08.460 --> 00:24:17.370
Paul McCartney: Part of what happens when we're trying to think about these things is we miss the simple answer right. Where's look so focused on looking at the data, the planes that made it back.

121
00:24:17.640 --> 00:24:26.400
Paul McCartney: That we don't take a step back and say, Who is it that we really care about. We don't really care about the planes that made it back, right, because they made it back. They did their job.

122
00:24:26.640 --> 00:24:37.260
Paul McCartney: We actually care about the who didn't make it back. So it's, it's all about taking one step back from the data and asking these actually very broad stroke questions.

123
00:24:38.340 --> 00:24:43.350
Paul McCartney: So our second question is, what what is, what is it that we really want to know if our data.

124
00:24:44.010 --> 00:24:52.170
Paul McCartney: Uber, there was an Uber ban in London Transport for London office. The authorizing authority for all taxis in London band Uber.

125
00:24:52.530 --> 00:25:03.180
Paul McCartney: Now, there's a lot of questions about why exactly they did it. But why they said they did it. Is that Uber was dangerous Uber had become associated with sexual assaults. I remember I was in London.

126
00:25:03.480 --> 00:25:13.920
Paul McCartney: I was getting an Uber. I was on the phone with my father and I said, Dad. I'll call you back. And he said, No, no, no. Liberty. Where are you, I said, I'm getting into Uber. He goes no, I've heard those are so dangerous in London. You can't get into what

127
00:25:14.130 --> 00:25:25.740
Paul McCartney: It's like 4pm on a Tuesday. But anyway, the public believed that Uber was dangerous the public truly believed it. So how, how did the public come to believe that Uber was dangerous.

128
00:25:26.160 --> 00:25:33.900
Paul McCartney: Well, the London taxi drivers Association, which is what you think of when you think of a black cab in London. They put up an advertisement.

129
00:25:34.620 --> 00:25:42.330
Paul McCartney: Last year there are 154 rapes and sexual assaults by many cab drivers in London at least 32 of these Uber drivers.

130
00:25:42.600 --> 00:25:48.240
Paul McCartney: There's also an image of a girl her makeup is streaming down her face. She is clearly just been sexually assaulted.

131
00:25:48.570 --> 00:25:59.970
Paul McCartney: I just wanted to go home. Don't take a risk with a mini cap that's an incredibly powerful advertisement. And if you notice the Metropolitan Police. The London Police logo.

132
00:26:00.210 --> 00:26:05.640
Paul McCartney: And the Transport for London office logo are both at the bottom of this ad incredibly powerful.

133
00:26:05.880 --> 00:26:16.740
Paul McCartney: And just do us a little bit of vocab when they say taxis taxis are black cabs, which are what you think of when you think of a London cab and mini caps that's any other type of private car transportation

134
00:26:17.370 --> 00:26:24.630
Paul McCartney: Uber's included so when they say 154 rapes and sexual assaults by mini cab drivers in London, they mean everything but blackcaps

135
00:26:25.080 --> 00:26:28.560
Paul McCartney: Very powerful advertisement. The problem is that it wasn't true.

136
00:26:29.130 --> 00:26:42.660
Paul McCartney: What the freedom of information request act actually said is that there were 154 allegations of rape or sexual assault, where the suspect was alleged to be a taxi driver that includes blackcaps 32 of these or by an Uber driver.

137
00:26:43.920 --> 00:26:53.430
Paul McCartney: So clearly the black cab Association had taken themselves out of this when they were asked about this. They said, oops, sorry clerical error.

138
00:26:54.210 --> 00:27:10.500
Paul McCartney: Oh, we'll take it down and they did and they put up another one last year there 32 allegations of rape or sexual assault made against Uber drivers, the same image of the girl her makeup streaming down her face. She has clearly just been sexually assaulted. I just wanted to go home.

139
00:27:11.970 --> 00:27:19.770
Paul McCartney: Why up your risk with a mini cab. Now, it's true. The information is true. But, what question do we really want to know of our data.

140
00:27:21.030 --> 00:27:31.380
Paul McCartney: Do you really up your risk. So let's take a look at the very simple numbers. We were given the wrong number of salts 32 by Uber drivers 154 total

141
00:27:31.650 --> 00:27:36.600
Paul McCartney: But is that really what we want to know of our numbers. Is that really what we want to know of our data.

142
00:27:37.110 --> 00:27:48.540
Paul McCartney: If Uber was responsible for 32 sexual assaults, but only did 32 journeys, the entire year in London, they would be very dangerous. There's 100% chance you'll be sexually assaulted. If you get an Uber.

143
00:27:48.900 --> 00:27:54.660
Paul McCartney: What if they did millions of journeys. What if they did many more than all of the others. So let's take a look.

144
00:27:55.020 --> 00:28:04.830
Paul McCartney: Proportion of sexual assaults by Uber drivers 32 by Uber 154 total. So they are Uber's responsible for 20% of a sexual assaults in London.

145
00:28:05.340 --> 00:28:15.600
Paul McCartney: But how many journeys are they responsible for number of journeys in London and any kind of taxi, including Uber's 3,000,001 million of those are completed by Uber.

146
00:28:16.020 --> 00:28:31.740
Paul McCartney: So Uber is responsible for 33% of the journeys, but only 20% of the sexual assaults, meaning that Uber is actually a safer way to get around than any other type of tax.

147
00:28:32.640 --> 00:28:39.300
Paul McCartney: And what about these headlines, the number of cab drivers charged with violence or sexual offenses in London. Is it a five year high

148
00:28:39.570 --> 00:28:51.060
Paul McCartney: Trying to say that with the introduction of Uber London has taxis have gotten much less safe well in 2015 there 136 reports of rape or sexual assault by taxis. When this headline was written.

149
00:28:51.480 --> 00:29:07.200
Paul McCartney: And what is the definition of a five year high, it means it was just as high five years ago in 2009 three years before Uber even started there 136 reports of rape or sexual assault by taxi drivers Uber had nothing to do with making it more unsafe.

150
00:29:07.740 --> 00:29:15.090
Paul McCartney: Now this seems like an unfortunate situation for Uber. But there's more to it. There's 3.5 million customers who last and arguably better product.

151
00:29:15.480 --> 00:29:24.600
Paul McCartney: 40,000 jobs are potentially lost from this and most Uber drivers and lease or contract higher their cars and then obviously the revenue for Uber in London.

152
00:29:24.930 --> 00:29:33.660
Paul McCartney: So what we really want to know of our data, the raw numbers. The proportions, the relative proportions changes the entire analysis.

153
00:29:34.650 --> 00:29:41.910
Paul McCartney: So now we'll do one more example of what that's a little bit lighter and my mother. My mother was very excited when she saw these headlines.

154
00:29:42.210 --> 00:29:53.850
Paul McCartney: Chocolate can stave off all simers as cocoa, the brain drug of the future chocolate improves brain function. This is about a year and a half ago, my mother was ecstatic. She called me. She said, liberty, I told you so.

155
00:29:54.720 --> 00:30:08.910
Paul McCartney: This is amazing. And she asked me the question that we probably wanted to ask of the data. How much chocolate. Can you look back at the study liberty. How much chocolate. Can I actually get to eat.

156
00:30:09.810 --> 00:30:21.510
Paul McCartney: In order to potentially reduce my risk. So that was the question she asked, and that is what we want to know. Right. How much chocolate. Do I get to eat to potentially reduce my risk.

157
00:30:21.960 --> 00:30:30.930
Paul McCartney: Well, it's obviously not chocolate. That's what reduces our risk. It's a bioactive called flavanols and flavanols are in chocolate. They're also in red wine.

158
00:30:31.620 --> 00:30:43.230
Paul McCartney: And so the question really is, is how many flavanols. Do I have to eat every day. And that's 510 milligrams. So unless you're going to take a five and all pill. You want to know how many flavanols are in chocolate.

159
00:30:43.890 --> 00:30:52.050
Paul McCartney: So let's say you, um, you're not really a chocolate person, but you might drink, eat some cocoa powder, you know, put it in, mix it into water a little hot chocolate.

160
00:30:52.500 --> 00:30:58.470
Paul McCartney: And you'd have to have 20 cups of hot chocolate every day in order to potentially reduce your risk.

161
00:30:58.710 --> 00:31:05.730
Paul McCartney: If you don't like hot chocolate and your dark chocolate person you'd have to have 1600 calories of dark chocolate every day.

162
00:31:06.030 --> 00:31:12.810
Paul McCartney: And if you're like me and you like milk chocolate. That's 3900 calories every day of milk chocolate.

163
00:31:13.050 --> 00:31:24.750
Paul McCartney: In order to potentially reduce your risk. Now, I'm not saying I couldn't do that. Okay, but I am saying that I would die of something else, way before I had to worry about getting Alzheimer's or dementia.

164
00:31:25.530 --> 00:31:41.790
Paul McCartney: And yes, this as well as the previous example, I'm looking at the chat does have enormous really really fascinating correlations to health care and we're actually going to do one of those examples. Next, especially with Kobe that I think should be interesting for everyone to see.

165
00:31:42.960 --> 00:31:51.840
Paul McCartney: So the question of what we really want to know what we care about death by chocolate yes 3900 calories a day. I think we could do it for a little while, but it may not be great.

166
00:31:52.110 --> 00:31:57.720
Paul McCartney: And I also I, you know, when I was looking back at this study from my mom, I thought, you know, I wonder who funded

167
00:31:58.110 --> 00:32:12.810
Paul McCartney: This study who wanted us to think that chocolate was so great for us. And it's amazing that Mars center for cocoa health science was in charge of the research for this one. They just, you know, so kind of them to want us to, you know, have their products do good for us very frightened.

168
00:32:14.400 --> 00:32:21.870
Paul McCartney: So we get to our third question we have, who is the data. What do we really want to know, and we get to how is it interpreted

169
00:32:22.170 --> 00:32:29.550
Paul McCartney: So french fries. I like chocolate. But I like French fries, a lot better and I saw this this headline come out eight year study

170
00:32:29.790 --> 00:32:37.830
Paul McCartney: Finds heavy french fry eaters have double the chance of death could french fries be killing you french fries are killing you.

171
00:32:38.130 --> 00:32:46.410
Paul McCartney: This is true. According to a peer reviewed study published in the American Journal of Clinical Nutrition and what the journal actually said

172
00:32:47.070 --> 00:32:54.270
Paul McCartney: Is that if you eat any form of fried potato more than twice a week, which means three times per week or more you double your risk of death.

173
00:32:54.660 --> 00:33:06.450
Paul McCartney: And it's true. That is what the journal said, and I went back to the study. So let's, let's start with our questions who well in the study. The average person was a 60 YEAR OLD MAN Okay.

174
00:33:07.170 --> 00:33:17.670
Paul McCartney: And what we really want to know is, we want to know what the differences for risk of death of a 60 year old man, if you eat no potatoes. No french fries versus if you do

175
00:33:18.030 --> 00:33:29.280
Paul McCartney: And that is doubling your risk of death. So our COO and our what makes sense. The question is, is how is it interpreted. So let's look at it a little bit of a different way than doubling your risk of death.

176
00:33:29.820 --> 00:33:35.220
Paul McCartney: If you're a 60 year old man, your risk of death at any point in time, regardless of how much you eat.

177
00:33:35.880 --> 00:33:47.820
Paul McCartney: Is 1% meaning that if I line up 160 year old men. One of them will die in the next year, just by virtue of the fact that they're 60 and their male sorry 60 year old man apologize but it's going to be better at the end.

178
00:33:48.570 --> 00:34:02.190
Paul McCartney: Now, if these 100 men eat french fries three times per week or more for their entire lives instead of one of them dying.

179
00:34:03.180 --> 00:34:15.390
Paul McCartney: To will we double our risk of death instead of one, two, which is still bad. Okay, but it sounds a whole lot better to go from a 1% to a 2% then doubling your risk of death.

180
00:34:16.320 --> 00:34:19.260
Paul McCartney: And I also, you know, I don't know about you guys, but when I eat french

181
00:34:19.530 --> 00:34:28.950
Paul McCartney: Like I eat french fries. I love them, but I don't really just eat french fries. Right. I have like a couple of beers. I have a big old juicy cheeseburger right there with me.

182
00:34:29.250 --> 00:34:36.390
Paul McCartney: And you know if I'm eating french fries three times per week or more, I'm not sure I'm like eating perfectly healthy. The rest of the time. Okay.

183
00:34:36.570 --> 00:34:46.290
Paul McCartney: I may not exactly be you know out there running five miles per day. If I'm eating french fries three times per week or more. So could it potentially be something else that has an effect on this.

184
00:34:47.220 --> 00:34:54.960
Paul McCartney: So that how we interpret, whether it's double risk of death or one in 100 to two and 100 and these dudes get to eat french fries. All time

185
00:34:55.500 --> 00:35:03.360
Paul McCartney: changes how we see this data. Let's look at another example. And this brings us to the covert testing that we were discussing here earlier.

186
00:35:03.690 --> 00:35:12.210
Paul McCartney: And yes, it is too bad that we can't rely on news outlets, you really have to think about these things and ask these questions yourself, which is very, very difficult.

187
00:35:12.960 --> 00:35:19.230
Paul McCartney: Okay, I have the antibodies. So it's safe. If we hang out. We now have an antibody test for coven

188
00:35:19.470 --> 00:35:28.290
Paul McCartney: Meaning that if you've had coven you take the antibody test. If you have the antibodies. The idea is that you are then immune from coven and you also cannot pass it on to other people.

189
00:35:28.800 --> 00:35:36.930
Paul McCartney: For the purposes of this will assume that's true that if you have antibodies. You can you assume that you're immune and you cannot pass it on to other people.

190
00:35:37.290 --> 00:35:46.920
Paul McCartney: And I've had people say this to me. I've had friends say this to me. I have the antibodies. So it's safe. We can hang out. You can be around me and then go be around your elderly parents, no problem.

191
00:35:47.550 --> 00:36:05.220
Paul McCartney: So the question is, is that true, how good is the testing. So the CDC put out guidance to the general public about these antibody tests. They said, and a population or the prevalence is 5% a test with 90% sensitivity and 95% specificity will yield the positive predictive value of 49%

192
00:36:06.270 --> 00:36:18.090
Paul McCartney: Sorry. You think the general person that's taking an antibody test has any idea what that means include. I mean, it takes me and this is what I do for a living. And it takes me a while to sit down there and puzzle out what this means.

193
00:36:18.660 --> 00:36:23.670
Paul McCartney: How are people supposed to really understand this. Yes, this is definitely where the headache comes on. Thank you.

194
00:36:24.360 --> 00:36:38.220
Paul McCartney: So let's take a step back and think about what question we really want to know the first test approved by the FDA for coven 19 antibody testing as sent on the CDC website is 95% accurate.

195
00:36:38.790 --> 00:36:44.490
Paul McCartney: What we want to know is what is the chance if your friend comes to you and says, I have the antibodies, it's safe to hang out.

196
00:36:44.910 --> 00:36:52.470
Paul McCartney: What you want to know is what is the chance that an individual actually has the antibodies, assuming they test positive

197
00:36:53.130 --> 00:37:02.580
Paul McCartney: Most people would assume based upon the CDC website is that it's 95% the test is 95% accurate. So there's a 95% chance that they have the antibodies and then it's fine.

198
00:37:03.690 --> 00:37:16.080
Paul McCartney: Let's take a closer look. If you have an antibody test. There are four possible outcomes outcome. One is you are positive and you test positive the test did its job. You're all good.

199
00:37:16.710 --> 00:37:22.800
Paul McCartney: Outcome to is that you are negative for antibodies and you test negative again the test did its job.

200
00:37:23.340 --> 00:37:31.650
Paul McCartney: But because the test is not 100% accurate. There are two other possible outcomes. The first is a false negative

201
00:37:32.070 --> 00:37:38.730
Paul McCartney: That means the test says you don't have the antibodies test negative. But you do have them the falls apart.

202
00:37:39.390 --> 00:37:45.360
Paul McCartney: Now, that one's not that dangerous, right. It's kind of annoying because you wish you knew that you had the antibodies and you can go out and do stuff.

203
00:37:45.600 --> 00:37:53.400
Paul McCartney: But you're not going to pass the disease on to, and you're going to pass the virus on to anyone else because you're going to think that you don't have the end the body. So you need to stay home.

204
00:37:54.180 --> 00:38:00.540
Paul McCartney: But there's a fourth option, a false positive, the test says you have the antibodies, but you don't

205
00:38:00.990 --> 00:38:10.230
Paul McCartney: And this is the really dangerous one. Because you're going to think that you're going to your immune, you're going to think you can't pass it on to anyone else. And you're going to go out into the wide world and pass it on.

206
00:38:11.520 --> 00:38:18.270
Paul McCartney: So the question is, how often does this happen. So let's let's look. Let's take a real scenario.

207
00:38:18.690 --> 00:38:28.170
Paul McCartney: 5% of the population has coded 19 that's what the CDC meant when they said 5% prevalence, meaning that they 5% is had it and we'll test positive for it.

208
00:38:28.710 --> 00:38:39.150
Paul McCartney: And the coven 19 antibody test is 95% accurate. So those are two assumptions and starting points. So let's say we have a population of thousand people. Let's say it's 1000 people at work.

209
00:38:40.020 --> 00:38:54.150
Paul McCartney: So if there's 5% prevalence in the population 5% of these people have had coven and will test positive for it 5% of 1000 is 50 people so 50 people have antibodies and we'll test positive for tested its job.

210
00:38:55.050 --> 00:39:00.360
Paul McCartney: But the test is only 95% accurate meaning 5% of the time, it won't be accurate.

211
00:39:00.840 --> 00:39:15.930
Paul McCartney: So we will have a 5% false positive rate, people will falsely test positive, it will tell them that they have the antibodies, but they don't 5% of 1000 is again 50 so we have 50 people who will falsely test positive

212
00:39:16.890 --> 00:39:29.280
Paul McCartney: Now out of our thousand people all 100 of these people will test positive all 100 old test positive, but only 50 of them actually have it.

213
00:39:30.060 --> 00:39:42.240
Paul McCartney: Meaning there's only a 50% chance that you actually have the antibodies. So back to our original question of what is the chance to be an individual actually has the antibodies, assuming they test positive

214
00:39:43.230 --> 00:39:51.210
Paul McCartney: 50%. That's it. It's the same as a toss of a coin. So when we think that if we have the antibodies. We can go back out into the world.

215
00:39:51.750 --> 00:40:02.160
Paul McCartney: There's a 5050 chance that it won't work. Yes. Not all 1000 people get the test that is true, but we're going, we're basing this idea of antibody testing on that it will help us get back to work.

216
00:40:02.580 --> 00:40:19.710
Paul McCartney: And so we would test everyone in the population and how it, but people who test negative impact this style at all in general that number for this 95% accurate what they meant was 5% false positives and 5% false negatives. So there would also be a large issue with that as well.

217
00:40:21.870 --> 00:40:22.680
Paul McCartney: Okey dokey.

218
00:40:24.750 --> 00:40:35.310
Paul McCartney: So, how we interpret the data, you know, CDC put out that statement, but how we interpret it as 95% accurate versus actually 5050 changes the entire way that we look at the situation.

219
00:40:36.600 --> 00:40:47.280
Paul McCartney: So now we get to our final example of how and my favorite one finished baby boxes in 2013 the BBC put out this article Why finished babies sleep in cardboard boxes.

220
00:40:47.760 --> 00:40:56.430
Paul McCartney: It was an article documenting the finished policy of giving every mother a cardboard box baby supplies and the baby would use the box as a bed.

221
00:40:57.300 --> 00:41:10.020
Paul McCartney: And this is a really interesting example of what happened because it exploded all over the place. People were talking about these baby boxes and for me, when my Molly, I will be right back to you. I'm going to write outside talk about that at the end.

222
00:41:11.790 --> 00:41:23.460
Paul McCartney: But inside this article was a graph and it showed Finland's incredible decrease in infant mortality rate incredible progress from 1935 down here to 2010

223
00:41:23.910 --> 00:41:31.860
Paul McCartney: And it also included Finland's and current infant mortality rate which is two and 1000 versus the rest of the world, which is 32 and 1000

224
00:41:32.340 --> 00:41:38.100
Paul McCartney: So really incredible based upon this policy of sending every mother a baby box.

225
00:41:38.730 --> 00:41:51.930
Paul McCartney: And it sparked an entire industry finished baby boxes British baby boxes. I actually went to a shower recently and the girl, my friend who was having a baby got two baby boxes at this whole industry.

226
00:41:52.380 --> 00:42:01.980
Paul McCartney: And it's incredible really this box this cardboard box that can save a baby's life. It's not just any cardboard box. It's an $850 cardboard box.

227
00:42:02.610 --> 00:42:14.130
Paul McCartney: I'm not really sure what they print on that thing. But inside of it actually looks got one to look at it and I'm inside. It has six diapers, which I'm I think any parents would be able to decide how long six diapers last

228
00:42:14.700 --> 00:42:19.410
Paul McCartney: Like two one Z's. A couple books. So really, the, the whole thing is this cardboard box.

229
00:42:20.760 --> 00:42:28.830
Paul McCartney: Is your baby slept one baby slept in a dresser drawer exactly same concept but you know i i would admit I hope the dresser Jordan cost 800 bucks, but you never know.

230
00:42:29.670 --> 00:42:46.680
Paul McCartney: And so, but, you know, okay, if we really believed that this box would save your child's life would save any child's life, you'd say fine 800 bucks. No problem. You would do anything to get that box anything. So the question is, does it

231
00:42:47.970 --> 00:42:55.350
Paul McCartney: Let's take a look back at this exact same graph and how we're going to interpret this data and how we're going to interpret this graph.

232
00:42:55.890 --> 00:43:04.290
Paul McCartney: In 1938 Finland had a higher infant mortality profile, then it's other Nordic neighbors and it decided it needed to do something about it.

233
00:43:04.680 --> 00:43:23.040
Paul McCartney: So it went on this incredible marketing campaign convincing others rich, poor educated or uneducated that they if they had their kids sleeping this baby box back kids slept in it they be fine. They'd survive, but this would save their child's life.

234
00:43:24.300 --> 00:43:33.300
Paul McCartney: And when every mother was convinced of this and wanted this baby box. The finished government said, you know, there's actually a catch.

235
00:43:33.990 --> 00:43:41.190
Paul McCartney: In order to get this baby box every mother will get one, but you have to go to prenatal education class.

236
00:43:42.090 --> 00:44:02.010
Paul McCartney: So in 1944 the year before the box came out 31% finished and others receive Prenatal Education in 1945 the year after 86% of finished mothers received Prenatal Education. It wasn't the box at all. It was education and general progress of info mortality rates across the world.

237
00:44:03.090 --> 00:44:09.630
Paul McCartney: And the reason we know this is because the infant mortality profile for rich, poor educated and uneducated finished mothers.

238
00:44:09.900 --> 00:44:24.420
Paul McCartney: Is the same as the infant mortality profile for rich and educated mothers in the US, the difference is born on educated mothers in the US have a much higher infant mortality profile. Now you can forgive industry for

239
00:44:25.440 --> 00:44:30.330
Paul McCartney: You know, deciding to profit and go, go forth and conquer off of these finished baby boxes.

240
00:44:31.170 --> 00:44:40.290
Paul McCartney: But you would think governments and other governments would sort of look into this sort of how this these baby boxes really worked before embarking upon a scheme.

241
00:44:40.590 --> 00:44:59.820
Paul McCartney: To send out baby boxes but no in a baby boxes were sent out in Essex in Birmingham and Scotland. They piloted a program in 2016 and now every single mother and Scotland receives a baby box. No. Prenatal Education required to the tune of I think $13 million of taxpayer money.

242
00:45:01.020 --> 00:45:07.800
Paul McCartney: But you know, that's the UK. We're America or smarter our government would definitely look into this stuff before piloting these baby boxes.

243
00:45:08.160 --> 00:45:30.630
Paul McCartney: Except they don't US states introduced baby boxes to help combat infant mortality in 2017 Alabama New Jersey and Ohio sent out baby boxes to the tune of 15,000,020 6,000,030 $5 million tons and tons of taxpayer money wasted with no Prenatal Education required

244
00:45:32.160 --> 00:45:40.050
Paul McCartney: And if someone had simply asked how is this interpreted. How does, what does this graph really mean we wouldn't be here.

245
00:45:40.530 --> 00:45:46.470
Paul McCartney: And as Alonso asks, How do you get to think to all the questions that are not intuitive to the data presented

246
00:45:46.950 --> 00:45:57.210
Paul McCartney: I know these questions seems stupid who what and how but I am telling you they work if you just take a step back and think, Who is this data about

247
00:45:57.540 --> 00:46:07.650
Paul McCartney: What are we really trying to ask of it and how should we really be interpreting this, it may not give you the answers. It may not make us. It's not going to make you a statistician

248
00:46:07.980 --> 00:46:12.990
Paul McCartney: But it will give you a feeling for whether the veracity of this data really need something

249
00:46:13.860 --> 00:46:24.870
Paul McCartney: And this this example leads us to our fourth question of why, why do we care and I want to, I want to use the same baby box numbers. And I want to say, you know,

250
00:46:25.350 --> 00:46:29.640
Paul McCartney: I don't know the difference between 26,000,035 million except that it's 9 million

251
00:46:29.940 --> 00:46:37.680
Paul McCartney: These numbers don't mean anything to me and our jobs and our work and newspapers, we see these numbers. Every time we see billions. We see trillions.

252
00:46:37.890 --> 00:46:50.130
Paul McCartney: For a lot of states 15,000,035. These are rounding errors for states for companies. How do we have a we make these numbers mean something. Why should we care about this money that's lost

253
00:46:51.030 --> 00:47:04.800
Paul McCartney: And I would say that going along the lines of anyone looking at this would be interested in sort of Child Health and baby health that we somehow figure out a way to make those numbers mean something in terms of that in terms of their opportunity cost as Mandy says

254
00:47:05.340 --> 00:47:12.210
Paul McCartney: So how do we do that, I would say, then instead of saying that Alabama wasted $15 million of taxpayer money.

255
00:47:12.600 --> 00:47:29.580
Paul McCartney: They could have paid for diapers for a year for 30,000 babies or New Jersey could have bought baby food for a year for 40,000 babies or Ohio could have paid a year salary for 800 new child social care workers.

256
00:47:29.880 --> 00:47:39.180
Paul McCartney: We need to turn these numbers into something that matters to people into something that people understand and personally matters to them.

257
00:47:40.110 --> 00:47:46.860
Paul McCartney: And that brings me to our last example you know we've talked this whole time about negative things you know the right you know

258
00:47:47.130 --> 00:48:00.000
Paul McCartney: About the, you know, all the manipulative things bad things sneaky things. But there's also incredible things that we can do. There's really incredible things we can do with actually making people care about the numbers.

259
00:48:00.810 --> 00:48:09.240
Paul McCartney: Or in the most severe refugee crisis since world war two and it's only growing UNHCR, the UN Refugee agencies budget for 2016 was $8

260
00:48:09.690 --> 00:48:18.090
Paul McCartney: Billion, but they only got 3 billion. That's $5 billion needed to help people. So what do they do they need to figure out a way to raise more money.

261
00:48:18.540 --> 00:48:27.030
Paul McCartney: That is, but as what needs to be done for this refugee crisis. So how do they do it, and I'm going to show you a very disturbing image. Next, so please. Just be ready for that.

262
00:48:28.560 --> 00:48:37.920
Paul McCartney: This is Alan Curtis. He's a three year old Syrian boy who in 2015 was found drowned on a Turkish beach and his family were Syrian refugees fleeing to Europe.

263
00:48:38.550 --> 00:48:59.640
Paul McCartney: This pictures unfathomably horrible event is really what sparked the world's discussion of the Syrian refugee crisis and one would imagine. I mean, how could you not look at that photo and feel sort of a deep on unbelievable sadness and it did increase donations, but not for very long.

264
00:49:00.840 --> 00:49:12.330
Paul McCartney: Three days was how long this image stayed in people's minds. There's absolutely horrible, horrible tragedy, and it was three days that a picture was able to see stay in people's minds.

265
00:49:12.780 --> 00:49:22.110
Paul McCartney: So we decided that we need to figure out what does stay in people's minds what works, what makes them care about the crisis or the issue longer

266
00:49:22.920 --> 00:49:35.160
Paul McCartney: So we did a study and what works and what doesn't. So we call people and we ask them questions and you say, which one of these does this increase or decrease your affinity towards the crisis.

267
00:49:35.760 --> 00:49:45.390
Paul McCartney: So if someone asks you, refugees undergo stringent security checks. Would that make you feel better about refugees or worse and take a second and think what you think most people would feel

268
00:49:47.700 --> 00:49:55.260
Paul McCartney: This question surprised me. It actually decreased people's affinity for the cause, because it reminded them that there are security issues.

269
00:49:56.310 --> 00:50:01.080
Paul McCartney: Refugees more likely to graduate college and secure jobs than non refugees.

270
00:50:02.220 --> 00:50:09.390
Paul McCartney: Is that going to increase or decrease people support in this case that decreased Democratic support but increased Republican support.

271
00:50:10.530 --> 00:50:12.450
Paul McCartney: Nearly half of refugees or children.

272
00:50:13.650 --> 00:50:23.610
Paul McCartney: Increased all support Albert Einstein was a refugee think it increased or decreased support it increased all support. We did a test on Catholics.

273
00:50:24.240 --> 00:50:37.980
Paul McCartney: 60 million to displace 21 million refugees are fleeing their homes and then we had another one that said, Jesus was a refugee, the numbers had no change in support. Jesus was a refugee had an large increase

274
00:50:38.430 --> 00:50:50.760
Paul McCartney: What this told us is that if you say there is a global refugee crisis. They're 16 million displaced. No one cares right these are fleeting numbers. They mean nothing to us and it goes right out of our head.

275
00:50:51.390 --> 00:51:02.250
Paul McCartney: But if we can take the numbers and have them say this is the way it impacts you and what you care about people will become donors, people are affected, and they will remember

276
00:51:03.450 --> 00:51:11.820
Paul McCartney: So we did a campaign during the major league baseball playoffs for each team that you would be watching, we put up their stadium and the number of people.

277
00:51:12.060 --> 00:51:23.820
Paul McCartney: 42,000 new people flee their homes on a daily basis. This is the same size as the crowd that you are watching on TV and this case at the Minute Maid Park, home of the Houston Astros

278
00:51:24.450 --> 00:51:31.050
Paul McCartney: It let us take this big number 42,000 people flee their home every day. That means nothing to anyone.

279
00:51:31.680 --> 00:51:41.040
Paul McCartney: And give it a visual from something that people care about, they are watching this stadium, they are watching this crowd. They can see all these people

280
00:51:41.550 --> 00:51:49.590
Paul McCartney: And it meant something it increase donations by 100,000 recurring donors. People, who keep giving

281
00:51:50.580 --> 00:52:03.900
Paul McCartney: If you are able to tell good numerical stories. If you're able to not just take the data analysis, but actually show the why, why we should care about it and make it mean something to people.

282
00:52:04.200 --> 00:52:16.320
Paul McCartney: Then, whether it's for engagement action donation customers whatever you're trying to do. If those numbers can impact someone personally, you can have a lasting decision for them.

283
00:52:19.770 --> 00:52:33.090
Paul McCartney: Really overall what this says is, we come back to data ism and humanism, you know, data gives us incredible insights to things. We'd never be able to see, but we need to retain our own experience and our own tuition.

284
00:52:33.390 --> 00:52:49.770
Paul McCartney: And make sure that we were always asking the right questions of the data. The who the what the how and the, why should we care. And if we're able to do that then we really can deliver true value in both our personal and working moms. Thank you.

285
00:52:52.410 --> 00:53:02.130
Andrew Knight: Thank you very much liberty for sharing such a helpful way of thinking about numbers and I was wondering, in a couple minutes that we have. If you have any

286
00:53:02.670 --> 00:53:20.430
Andrew Knight: Like rules of thumb or your risks that you use when you're reading a news article or, you know, the latest piece of information that comes out about coven. Is there anything that that you do consciously to try to make your way through some of the distortion of numbers.

287
00:53:21.450 --> 00:53:28.830
Paul McCartney: I think the first and most important thing is to not believe any of it right off the bat, and I hate saying that because you don't want to be this.

288
00:53:29.100 --> 00:53:40.350
Paul McCartney: You know, sort of non believer, but you really can't believe it right off the bat, the biggest numbers. The 95% accurate or the double the risk of death. That's what makes you read the article.

289
00:53:40.620 --> 00:53:54.510
Paul McCartney: I will say, I think the headlines are almost always way worse than the article itself. A lot of times the article itself will have the caveats, and will have the the world. Well, if you look at it this way, the headlines never will.

290
00:53:55.020 --> 00:54:03.240
Paul McCartney: Because the headlines are really about getting people to read it. And in general, like I know for example. Whenever I write, I don't get to choose the headline. I have zero SEO for it.

291
00:54:03.600 --> 00:54:16.380
Paul McCartney: And it will be what is going to get people to read it and it's not going to have the well it's not a double a risk of death of you dying from French fries. It's actually you know headline. Oh, a 1% increase in risk of death. It just doesn't get you to read it.

292
00:54:18.180 --> 00:54:29.100
Andrew Knight: So it just takes like scrutinizing i mean i think i dropped something in the chat earlier that, you know, it gives me a headache sometimes to try to make my way through, what is the actual

293
00:54:30.090 --> 00:54:43.470
Andrew Knight: risk level that's being presented and of course the always important question that john has dropped in the in the chat to leave us with and maybe you could leave this as a cliffhanger. How do we win the lottery.

294
00:54:43.830 --> 00:54:44.760
Paul McCartney: Got to buy the book.

295
00:54:45.510 --> 00:54:46.170
Andrew Knight: gotta buy the

296
00:54:46.200 --> 00:54:47.310
Paul McCartney: Book. I'm kidding, I'm kidding.

297
00:54:48.900 --> 00:55:02.100
Paul McCartney: I actually deleted that example because I was running out of time. Get Away With Murder, you gotta go look at OJ it and it worked out. Sure. You really want to try that. But there's, there's a lot of questions about statistical change of samples.

298
00:55:03.360 --> 00:55:12.000
Andrew Knight: Well, thank you again so much for taking time to share these thoughts with us. And folks, if you can go down to the bottom of your zoom window, you'll see a

299
00:55:12.480 --> 00:55:25.380
Andrew Knight: button that says reactions. And so if you'd click that reactions button and let's give liberty, a virtual you know Round of applause for sharing her expertise with us.

300
00:55:26.820 --> 00:55:41.970
Andrew Knight: Certainly, if you are in person ensure we have here rockets. APPLAUSE So thank you so much everyone, hope you have a wonderful rest of your day and 15 minutes if this is your lunch hour to squeeze out and grab something to eat. So thanks everyone. See you in our next program.

