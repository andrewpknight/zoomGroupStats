% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/videoFaceAnalysis.R
\name{videoFaceAnalysis}
\alias{videoFaceAnalysis}
\title{Analyze the facial features within an exported Zoom video file}
\usage{
videoFaceAnalysis(
  inputVideo,
  recordingStartDateTime,
  sampleWindow,
  facesCollectionID = NA
)
}
\arguments{
\item{inputVideo}{string path to the video file (ideal is gallery)}

\item{recordingStartDateTime}{YYYY-MM-DD HH:MM:SS of the start of the recording}

\item{sampleWindow}{Frame rate for the analysis}

\item{facesCollectionID}{name of an AWS collection with identified faces}
}
\value{
data.frame with one record for every face detected in each frame
for each face, there is an abundance of information from AWS rekognition
}
\description{
Analyze the facial features within an exported Zoom video file
}
\examples{
\dontrun{
vid.out = videoFaceAnalysis(inputVideo="sample_gallery_video.mp4", 
recordingStartDateTime="2020-04-20 13:30:00", 
sampleWindow=30, facesCollectionID="group-r")
}
}
